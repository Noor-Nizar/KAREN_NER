{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:52:36.773696Z","iopub.status.busy":"2024-08-13T00:52:36.773296Z","iopub.status.idle":"2024-08-13T00:52:38.778235Z","shell.execute_reply":"2024-08-13T00:52:38.776985Z","shell.execute_reply.started":"2024-08-13T00:52:36.773665Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.\n"]}],"source":["!wandb off"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:52:38.780785Z","iopub.status.busy":"2024-08-13T00:52:38.780453Z","iopub.status.idle":"2024-08-13T00:52:38.881557Z","shell.execute_reply":"2024-08-13T00:52:38.880515Z","shell.execute_reply.started":"2024-08-13T00:52:38.780756Z"},"trusted":true},"outputs":[],"source":["import transformers\n","from transformers import AutoTokenizer\n","\n","model_name = \"hatmimoha/arabic-ner\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-13T00:52:38.883114Z","iopub.status.busy":"2024-08-13T00:52:38.882785Z","iopub.status.idle":"2024-08-13T00:52:38.890307Z","shell.execute_reply":"2024-08-13T00:52:38.889191Z","shell.execute_reply.started":"2024-08-13T00:52:38.883087Z"},"trusted":true},"outputs":[],"source":["def load_data(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        data = file.read().split('\\n\\n')  # Split sentences\n","    sentences = []\n","    labels = []\n","    for item in data:\n","        words = []\n","        tags = []\n","        lines = item.splitlines()\n","        for line in lines:\n","            if line:\n","                word, tag = line.split()\n","                words.append(word)\n","                tags.append(tag)\n","        sentences.append(words)\n","        labels.append(tags)\n","    return sentences, labels"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:52:38.893497Z","iopub.status.busy":"2024-08-13T00:52:38.893151Z","iopub.status.idle":"2024-08-13T00:52:38.904486Z","shell.execute_reply":"2024-08-13T00:52:38.903496Z","shell.execute_reply.started":"2024-08-13T00:52:38.893470Z"},"trusted":true},"outputs":[],"source":["def tokenize_and_align_labels(sentences, labels):\n","    tokenized_inputs = []\n","    tokenized_labels = []\n","\n","    for sentence, label in zip(sentences, labels):\n","        # Tokenize the input sentence with word-level tokenization\n","        tokenized_input = tokenizer(sentence, \n","                                    is_split_into_words=True, \n","                                    padding='max_length', \n","                                    max_length=64, \n","                                    truncation=True,\n","                                    return_tensors='pt')\n","\n","        word_ids = tokenized_input.word_ids()  # Map tokens back to their word index\n","        label_ids = []\n","        \n","        previous_word_idx = None\n","\n","        for word_idx in word_ids:\n","            if word_idx is None:\n","                label_ids.append(-100)  # Special tokens or padding tokens\n","            elif word_idx != previous_word_idx:\n","                label_ids.append(label[word_idx])  # Take the original label\n","            else:\n","                label_ids.append(label[word_idx].replace('B-', 'I-'))  # Make sure to align subwords with 'I-'\n","            \n","            previous_word_idx = word_idx\n","\n","        tokenized_inputs.append(tokenized_input)\n","        tokenized_labels.append(label_ids)\n","\n","    return tokenized_inputs, tokenized_labels"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:52:38.905932Z","iopub.status.busy":"2024-08-13T00:52:38.905618Z","iopub.status.idle":"2024-08-13T00:52:38.916081Z","shell.execute_reply":"2024-08-13T00:52:38.915155Z","shell.execute_reply.started":"2024-08-13T00:52:38.905902Z"},"trusted":true},"outputs":[],"source":["def create_label_mappings(labels):\n","    unique_labels = set(label for sublist in labels for label in sublist)\n","    label_to_id = {label: i for i, label in enumerate(unique_labels)}\n","    id_to_label = {i: label for label, i in label_to_id.items()}\n","    return label_to_id, id_to_label\n","\n","def convert_labels_to_ids(labels, label_to_id):\n","    return [[label_to_id.get(label, -100) for label in sublist] for sublist in labels]\n","\n","# def format_data_for_transformers(tokenized_inputs, tokenized_labels):\n","#     input_ids = [input[\"input_ids\"] for input in tokenized_inputs]\n","#     attention_masks = [input[\"attention_mask\"] for input in tokenized_inputs]\n","#     token_type_ids = [input[\"token_type_ids\"] for input in tokenized_inputs]\n","\n","#     formatted_data = []\n","#     for i in range(len(input_ids)):\n","#         formatted_data.append({\n","#             \"input_ids\": input_ids[i],\n","#             \"attention_mask\": attention_masks[i],\n","#             \"token_type_ids\": token_type_ids[i],\n","#             \"labels\": torch.tensor(tokenized_labels[i])\n","#         })\n","    \n","#     return formatted_data"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:52:38.917534Z","iopub.status.busy":"2024-08-13T00:52:38.917244Z","iopub.status.idle":"2024-08-13T00:52:38.998411Z","shell.execute_reply":"2024-08-13T00:52:38.997637Z","shell.execute_reply.started":"2024-08-13T00:52:38.917511Z"},"trusted":true},"outputs":[],"source":["from sklearn.utils import shuffle\n","\n","X, y = load_data(\"/kaggle/input/ner-tuning-keemet/processed_final_c.txt\")\n","X, y = shuffle(X, y, random_state=42)\n","\n","label_to_id, id_to_label = create_label_mappings(y)\n","\n","X_train, y_train = X[:128], y[:128]\n","X_test, y_test = X[128:], y[128:]\n","\n","X_train_tokenized, y_train_tokenized = tokenize_and_align_labels(X_train, y_train)\n","X_test_tokenized, y_test_tokenized = tokenize_and_align_labels(X_test, y_test)\n","\n","y_train_ids = convert_labels_to_ids(y_train_tokenized, label_to_id)\n","y_test_ids = convert_labels_to_ids(y_test_tokenized, label_to_id)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:52:39.010834Z","iopub.status.busy":"2024-08-13T00:52:39.010447Z","iopub.status.idle":"2024-08-13T00:53:03.800122Z","shell.execute_reply":"2024-08-13T00:53:03.799306Z","shell.execute_reply.started":"2024-08-13T00:52:39.010807Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-13 00:52:41.353420: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-13 00:52:41.353533: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-13 00:52:41.487490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b32a6158a645471a9d62174c6f0cc3c8","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84458bb2126a4c5081010666ee925967","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","from transformers import Trainer, TrainingArguments\n","import torch\n","\n","# Load the model and tokenizer\n","model = AutoModelForTokenClassification.from_pretrained(model_name)\n","\n","# Freeze the first 6 layers\n","for param in model.bert.encoder.layer[:6].parameters():\n","    param.requires_grad = False"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:53:03.801879Z","iopub.status.busy":"2024-08-13T00:53:03.801283Z","iopub.status.idle":"2024-08-13T00:53:03.818504Z","shell.execute_reply":"2024-08-13T00:53:03.817755Z","shell.execute_reply.started":"2024-08-13T00:53:03.801852Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class TokenizedDataset(Dataset):\n","    def __init__(self, X_tokenized, y_labels):\n","        self.input_ids = [item['input_ids'].squeeze(0) for item in X_tokenized]\n","        self.token_type_ids = [item['token_type_ids'].squeeze(0) for item in X_tokenized]\n","        self.attention_mask = [item['attention_mask'].squeeze(0) for item in X_tokenized]\n","        self.labels = [torch.tensor(label) for label in y_labels]\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_ids[idx],\n","            'token_type_ids': self.token_type_ids[idx],\n","            'attention_mask': self.attention_mask[idx],\n","            'labels': self.labels[idx]\n","        }\n","\n","\n","train_dataset = TokenizedDataset(X_train_tokenized, y_train_ids)\n","test_dataset = TokenizedDataset(X_test_tokenized, y_test_ids)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:53:03.822047Z","iopub.status.busy":"2024-08-13T00:53:03.821708Z","iopub.status.idle":"2024-08-13T00:53:03.826606Z","shell.execute_reply":"2024-08-13T00:53:03.825663Z","shell.execute_reply.started":"2024-08-13T00:53:03.822023Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","loader = DataLoader(train_dataset, batch_size=2, shuffle=False)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:53:03.827973Z","iopub.status.busy":"2024-08-13T00:53:03.827692Z","iopub.status.idle":"2024-08-13T00:53:03.914562Z","shell.execute_reply":"2024-08-13T00:53:03.913632Z","shell.execute_reply.started":"2024-08-13T00:53:03.827948Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=50,\n","    weight_decay=0.01,\n","    logging_steps=10,\n","    eval_steps=10,\n","    logging_dir='./logs',\n","#     no_cuda=True\n","    load_best_model_at_end = True,\n","    metric_for_best_model = 'eval_f1',\n","    save_strategy = \"epoch\",\n","    save_total_limit=1,\n",")\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:53:03.915979Z","iopub.status.busy":"2024-08-13T00:53:03.915706Z","iopub.status.idle":"2024-08-13T00:53:03.927585Z","shell.execute_reply":"2024-08-13T00:53:03.926693Z","shell.execute_reply.started":"2024-08-13T00:53:03.915955Z"},"trusted":true},"outputs":[],"source":["from transformers import EvalPrediction\n","from sklearn.metrics import classification_report\n","\n","def compute_metrics(p: EvalPrediction):\n","    predictions, labels = p.predictions, p.label_ids\n","    predictions = predictions.argmax(axis=-1)\n","    \n","    # Flatten the sequences for classification_report\n","    true_labels = [label for doc in labels for label in doc if label != -100]\n","    pred_labels = [pred for doc, true_doc in zip(predictions, labels) for pred, true in zip(doc, true_doc) if true != -100]\n","    \n","    # Generate the classification report\n","    report = classification_report(true_labels, pred_labels, labels=list(label_to_id.values()), target_names=list(label_to_id.keys()), output_dict=True, zero_division=0)\n","    \n","    # Return the metrics of interest\n","    return {\n","        'precision': report['macro avg']['precision'],\n","        'recall': report['macro avg']['recall'],\n","        'f1': report['macro avg']['f1-score']\n","    }\n","\n","def compute_metrics_2(p: EvalPrediction):\n","    predictions, labels = p.predictions, p.label_ids\n","    predictions = predictions.argmax(axis=-1)\n","    \n","    # Flatten the sequences for classification_report\n","    true_labels = [label for doc in labels for label in doc if label != -100]\n","    pred_labels = [pred for doc, true_doc in zip(predictions, labels) for pred, true in zip(doc, true_doc) if true != -100]\n","    \n","    # Generate the classification report\n","    report = classification_report(true_labels, pred_labels, labels=list(label_to_id.values()), target_names=list(label_to_id.keys()), output_dict=False, zero_division=0)\n","    \n","    print(report)\n","    # Return the metrics of interest\n","    return {\"done\": 1}"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:53:03.929206Z","iopub.status.busy":"2024-08-13T00:53:03.928887Z","iopub.status.idle":"2024-08-13T00:53:04.542500Z","shell.execute_reply":"2024-08-13T00:53:04.541642Z","shell.execute_reply.started":"2024-08-13T00:53:03.929172Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    compute_metrics=compute_metrics\n",")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T00:53:04.543882Z","iopub.status.busy":"2024-08-13T00:53:04.543600Z","iopub.status.idle":"2024-08-13T00:56:10.797311Z","shell.execute_reply":"2024-08-13T00:56:10.796200Z","shell.execute_reply.started":"2024-08-13T00:53:04.543857Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m URL not available in offline run\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [400/400 02:45, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>6.508733</td>\n","      <td>0.022727</td>\n","      <td>0.000518</td>\n","      <td>0.001012</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>7.527600</td>\n","      <td>3.179518</td>\n","      <td>0.035839</td>\n","      <td>0.031832</td>\n","      <td>0.033717</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.863700</td>\n","      <td>1.900326</td>\n","      <td>0.041810</td>\n","      <td>0.056474</td>\n","      <td>0.045018</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.738000</td>\n","      <td>1.492466</td>\n","      <td>0.156338</td>\n","      <td>0.138372</td>\n","      <td>0.110409</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.257500</td>\n","      <td>1.229505</td>\n","      <td>0.252598</td>\n","      <td>0.176951</td>\n","      <td>0.153734</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.257500</td>\n","      <td>1.031446</td>\n","      <td>0.328426</td>\n","      <td>0.327850</td>\n","      <td>0.290130</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.967700</td>\n","      <td>0.875782</td>\n","      <td>0.448541</td>\n","      <td>0.386006</td>\n","      <td>0.354163</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.782400</td>\n","      <td>0.767917</td>\n","      <td>0.455407</td>\n","      <td>0.449579</td>\n","      <td>0.419344</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.592300</td>\n","      <td>0.700209</td>\n","      <td>0.572263</td>\n","      <td>0.548955</td>\n","      <td>0.526949</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.478000</td>\n","      <td>0.611884</td>\n","      <td>0.679147</td>\n","      <td>0.662150</td>\n","      <td>0.654868</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.478000</td>\n","      <td>0.585984</td>\n","      <td>0.678819</td>\n","      <td>0.674915</td>\n","      <td>0.662869</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.378200</td>\n","      <td>0.541407</td>\n","      <td>0.676103</td>\n","      <td>0.696338</td>\n","      <td>0.678526</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.314800</td>\n","      <td>0.515839</td>\n","      <td>0.677232</td>\n","      <td>0.691042</td>\n","      <td>0.676296</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.244100</td>\n","      <td>0.523158</td>\n","      <td>0.708777</td>\n","      <td>0.721431</td>\n","      <td>0.703150</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.204600</td>\n","      <td>0.489399</td>\n","      <td>0.686800</td>\n","      <td>0.703463</td>\n","      <td>0.687150</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.204600</td>\n","      <td>0.505731</td>\n","      <td>0.689475</td>\n","      <td>0.707963</td>\n","      <td>0.690640</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.160000</td>\n","      <td>0.502534</td>\n","      <td>0.766383</td>\n","      <td>0.728205</td>\n","      <td>0.726735</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.137000</td>\n","      <td>0.492167</td>\n","      <td>0.781537</td>\n","      <td>0.731565</td>\n","      <td>0.729230</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.115200</td>\n","      <td>0.522255</td>\n","      <td>0.761595</td>\n","      <td>0.726505</td>\n","      <td>0.721997</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.100000</td>\n","      <td>0.491932</td>\n","      <td>0.794318</td>\n","      <td>0.737800</td>\n","      <td>0.742169</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.100000</td>\n","      <td>0.540095</td>\n","      <td>0.738559</td>\n","      <td>0.716055</td>\n","      <td>0.705438</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.080100</td>\n","      <td>0.514246</td>\n","      <td>0.780477</td>\n","      <td>0.748632</td>\n","      <td>0.743880</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.059100</td>\n","      <td>0.535575</td>\n","      <td>0.774523</td>\n","      <td>0.733930</td>\n","      <td>0.732152</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.055300</td>\n","      <td>0.531559</td>\n","      <td>0.770028</td>\n","      <td>0.740655</td>\n","      <td>0.735371</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.047300</td>\n","      <td>0.524799</td>\n","      <td>0.779859</td>\n","      <td>0.741559</td>\n","      <td>0.742042</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.047300</td>\n","      <td>0.566098</td>\n","      <td>0.765951</td>\n","      <td>0.729344</td>\n","      <td>0.726838</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.041300</td>\n","      <td>0.551888</td>\n","      <td>0.791948</td>\n","      <td>0.743859</td>\n","      <td>0.747513</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.036800</td>\n","      <td>0.553035</td>\n","      <td>0.779887</td>\n","      <td>0.742739</td>\n","      <td>0.741762</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.029500</td>\n","      <td>0.569962</td>\n","      <td>0.769679</td>\n","      <td>0.749167</td>\n","      <td>0.743292</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.027300</td>\n","      <td>0.549223</td>\n","      <td>0.783390</td>\n","      <td>0.756466</td>\n","      <td>0.753431</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.027300</td>\n","      <td>0.542914</td>\n","      <td>0.777817</td>\n","      <td>0.751092</td>\n","      <td>0.750062</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.023400</td>\n","      <td>0.538013</td>\n","      <td>0.783495</td>\n","      <td>0.749238</td>\n","      <td>0.752484</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.020000</td>\n","      <td>0.554669</td>\n","      <td>0.786059</td>\n","      <td>0.743051</td>\n","      <td>0.744810</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.020000</td>\n","      <td>0.570789</td>\n","      <td>0.777424</td>\n","      <td>0.736489</td>\n","      <td>0.736834</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.018500</td>\n","      <td>0.577331</td>\n","      <td>0.778367</td>\n","      <td>0.743729</td>\n","      <td>0.741038</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.018500</td>\n","      <td>0.571979</td>\n","      <td>0.783778</td>\n","      <td>0.743884</td>\n","      <td>0.743070</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.017000</td>\n","      <td>0.598017</td>\n","      <td>0.779520</td>\n","      <td>0.739908</td>\n","      <td>0.738880</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.016200</td>\n","      <td>0.604724</td>\n","      <td>0.771627</td>\n","      <td>0.737290</td>\n","      <td>0.734646</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.015600</td>\n","      <td>0.589897</td>\n","      <td>0.776381</td>\n","      <td>0.738412</td>\n","      <td>0.737767</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.013400</td>\n","      <td>0.597633</td>\n","      <td>0.774334</td>\n","      <td>0.738283</td>\n","      <td>0.736355</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.013400</td>\n","      <td>0.601135</td>\n","      <td>0.779014</td>\n","      <td>0.739374</td>\n","      <td>0.739081</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.012700</td>\n","      <td>0.602736</td>\n","      <td>0.782272</td>\n","      <td>0.739946</td>\n","      <td>0.740612</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.011300</td>\n","      <td>0.606262</td>\n","      <td>0.776821</td>\n","      <td>0.737321</td>\n","      <td>0.737240</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.014400</td>\n","      <td>0.609564</td>\n","      <td>0.776681</td>\n","      <td>0.747506</td>\n","      <td>0.747484</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.011700</td>\n","      <td>0.610943</td>\n","      <td>0.772187</td>\n","      <td>0.744530</td>\n","      <td>0.743739</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.011700</td>\n","      <td>0.607463</td>\n","      <td>0.773457</td>\n","      <td>0.746453</td>\n","      <td>0.745754</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.012400</td>\n","      <td>0.597511</td>\n","      <td>0.779421</td>\n","      <td>0.751352</td>\n","      <td>0.751419</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.012000</td>\n","      <td>0.592787</td>\n","      <td>0.777940</td>\n","      <td>0.750722</td>\n","      <td>0.750445</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.014500</td>\n","      <td>0.593020</td>\n","      <td>0.777940</td>\n","      <td>0.750722</td>\n","      <td>0.750445</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.012700</td>\n","      <td>0.593522</td>\n","      <td>0.777940</td>\n","      <td>0.750722</td>\n","      <td>0.750445</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=400, training_loss=0.4620898695103824, metrics={'train_runtime': 185.0299, 'train_samples_per_second': 34.589, 'train_steps_per_second': 2.162, 'total_flos': 209069533593600.0, 'train_loss': 0.4620898695103824, 'epoch': 50.0})"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-08-13T01:06:38.733699Z","iopub.status.busy":"2024-08-13T01:06:38.732681Z","iopub.status.idle":"2024-08-13T01:06:38.979606Z","shell.execute_reply":"2024-08-13T01:06:38.978507Z","shell.execute_reply.started":"2024-08-13T01:06:38.733659Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8/8 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m URL not available in offline run\n"]},{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     B-Units       0.82      0.74      0.78        38\n","       I-Age       0.88      1.00      0.93        21\n","    B-Prices       0.84      0.91      0.87        23\n","  I-Currency       0.82      0.54      0.65        26\n","  I-Quantity       0.50      0.67      0.57         3\n","     I-Units       0.88      0.80      0.84        65\n","     I-Dates       0.94      0.89      0.91        53\n","     I-Times       0.58      0.88      0.70        43\n","     B-Dates       0.86      0.71      0.77        17\n","     B-Times       0.56      0.77      0.65        13\n","       B-Age       1.00      1.00      1.00         6\n","  B-Currency       0.64      0.56      0.60        16\n","    B-Colors       1.00      0.38      0.55         8\n","  B-Quantity       0.81      0.74      0.77        34\n","    I-Prices       0.44      0.57      0.50        21\n","           O       0.97      0.96      0.96       483\n","\n","    accuracy                           0.88       870\n","   macro avg       0.78      0.76      0.75       870\n","weighted avg       0.89      0.88      0.88       870\n","\n"]},{"data":{"text/plain":["{'eval_loss': 0.5492228269577026,\n"," 'eval_done': 1,\n"," 'eval_runtime': 0.1924,\n"," 'eval_samples_per_second': 306.675,\n"," 'eval_steps_per_second': 41.583}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5533123,"sourceId":9161516,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
